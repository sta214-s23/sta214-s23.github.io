---
title: Logistic regression assumptions and diagnostics
output:
  xaringan::moon_reader:
    css: "lab-slides.css"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r, include=F}
library(knitr)
hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
   lines <- options$output.lines
   if (is.null(lines)) {
     return(hook_output(x, options))  # pass to default hook
   }
   x <- unlist(strsplit(x, "\n"))
   more <- "..."
   if (length(lines)==1) {        # first n lines
     if (length(x) > lines) {
       # truncate the output, but add ....
       x <- c(head(x, lines), more)
     }
   } else {
     x <- c(more, x[lines], more)
   }
   # paste these lines together
   x <- paste(c(x, ""), collapse = "\n")
   hook_output(x, options)
 })
```

### Class activity, Part I

.large[
[https://sta214-s23.github.io/class_activities/ca_lecture_12.html](https://sta214-s23.github.io/class_activities/ca_lecture_12.html)

.question[
* Simulate data with a potential outlier
* Assess the impact on estimated coefficients
]
]

---

### Class activity

.large[
.question[
How does an outlier influence the fitted regression model?
]
]

---

### Cook's distance

---

### Cook's distance in R

.large[
```{r, include=F}
x <- rnorm(100)
p <- exp(-1 + 2*x)/(1 + exp(-1 + 2*x))
y <- rbinom(100, 1, p)
```

```{r, eval=F}
x1 <- c(x, -2)
y1 <- c(y, 1)
m1 <- glm(y1 ~ x1, family = binomial)

plot(x1, cooks.distance(m1))
```

```{r, echo=F, fig.align='center', fig.width=7, fig.height=5}
x1 <- c(x, -2)
y1 <- c(y, 1)
m1 <- glm(y1 ~ x1, family = binomial)

plot(x1, cooks.distance(m1), cex = 1.2, pch=16)
```
]

---

### Cook's distance in R

.large[

```{r, eval=F}
x1 <- c(x, -5)
y1 <- c(y, 1)
m1 <- glm(y1 ~ x1, family = binomial)

plot(x1, cooks.distance(m1))
```

```{r, echo=F, fig.align='center', fig.width=7, fig.height=5}
x1 <- c(x, -5)
y1 <- c(y, 1)
m1 <- glm(y1 ~ x1, family = binomial)

plot(x1, cooks.distance(m1), cex = 1.2, pch=16)
```
]

---

### Addressing model issues

.large[
.question[
How should we handle outliers and influential points? Discuss with a neighbor for a few minutes, then we will discuss as a group.
]
]

---

### Summary

.large[
* Shape assumption
  * Diagnostics: empirical logit plots, quantile residual plots
  * Addressing violations: transformations
* Multicollinearity
  * Diagnostics: correlation matrix, scatterplot matrix, VIFs
  * Addressing violations: remove or combine some variables
* Outliers and influential points
  * Diagnostics: Cook's distance
  * Addressing violations: remove clear errors; otherwise report conclusions (p-values, confidence intervals, etc.) with and without potential outliers
]

---

### Class activity, Part II

.large[
[https://sta214-s23.github.io/class_activities/ca_lecture_12.html](https://sta214-s23.github.io/class_activities/ca_lecture_12.html)

.question[
* Explore a dataset on small business loans
* Perform diagnostics and build a model

Work with a neighbor on the class activity questions. We will discuss as a group towards the end of the class period. Note: some of the questions are open-ended, with multiple reasonable answers
]
]

---

### Correlation

```{r, include=F}
sba <- read.csv("~/Documents/Teaching/sta214-s23.github.io/class_activities/sba_small.csv")

library(tidyverse)
library(GGally)
library(car)
library(gridExtra)
```

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=8, fig.height=6}
sba %>%
  select(GrAppv, SBA_Appv, DisbursementGross,
         Term, NoEmp) %>%
  ggpairs(upper = list(continuous = "points"),
          lower = list(continuous = 
                         GGally::wrap(ggally_cor, stars = F))) +
  theme_classic()
```

.large[
.question[
How should we handle correlation in these variables?
]
]

---

### Empirical logit plots

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=8, fig.height=6}
logodds_plot <- function(data, num_bins, bin_method,
                         x_name, y_name, grouping = NULL, reg_formula = y ~ x){
  
  if(is.null(grouping)){
    dat <- data.frame(x = data %>% pull(x_name), 
                      y = data %>% pull(y_name),
                      group = 1)
  } else {
    dat <- data.frame(x = data %>% pull(x_name), 
                      y = data %>% pull(y_name),
                      group = as.factor(data %>% pull(grouping)))
  }
  
  if(bin_method == "equal_size"){
    logodds_table <- dat %>%
      drop_na() %>%
      arrange(group, x) %>%
      group_by(group) %>%
      mutate(obs = y,
             bin = rep(1:num_bins,
                       each=ceiling(n()/num_bins))[1:n()]) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  } else {
    logodds_table <- dat %>%
      drop_na() %>%
      group_by(group) %>%
      mutate(obs = y,
             bin = cut(x, 
                       breaks = num_bins,
                       labels = F)) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  }
  
  if(is.null(grouping)){
    logodds_table %>%
      ggplot(aes(x = mean_x,
                 y = logodds)) +
      geom_point(size=2) +
      geom_smooth(se=F, method="lm", formula = reg_formula) +
      theme_bw() +
      labs(x = x_name,
           y = "Empirical log odds") +
      theme(text = element_text(size=15))
  } else {
    logodds_table %>%
      ggplot(aes(x = mean_x,
                 y = logodds,
                 color = group,
                 shape = group)) +
      geom_point(size=2) +
      geom_smooth(se=F, method="lm", formula = reg_formula) +
      theme_bw() +
      labs(x = x_name,
           y = "Empirical log odds",
           color = grouping,
           shape = grouping) +
      theme(text = element_text(size=15))
  }
}

p1 <- logodds_plot(sba, 25, "equal_size", "Term",
             "Default")
p2 <- logodds_plot(sba, 25, "equal_size", "DisbursementGross",
             "Default")
p3 <- logodds_plot(sba, 25, "equal_size", "NoEmp",
             "Default")

grid.arrange(p1, p2, p3, ncol=2)
```

.large[
.question[
How does the shape assumption look?
]
]

---

### Trying some transformations

```{r, echo=F, message=F, warning=F, fig.align='center', fig.width=8, fig.height=6}
p1 <- sba %>%
  mutate(logDisbursement = log(DisbursementGross)) %>%
  logodds_plot(25, "equal_size", "logDisbursement", "Default")
p2 <- sba %>%
  mutate(sqrtDisbursement = sqrt(DisbursementGross)) %>%
  logodds_plot(25, "equal_size", "sqrtDisbursement", "Default")
p3 <- sba %>%
  mutate(logEmployees = log(NoEmp + 1)) %>%
  logodds_plot(25, "equal_size", "logEmployees", "Default")
p4 <- sba %>%
  mutate(sqrtEmployees = sqrt(NoEmp)) %>%
  logodds_plot(25, "equal_size", "sqrtEmployees", "Default")

grid.arrange(p1, p2, p3, p4, ncol=2)
```

---

### Model output

```{r, output.lines = 10:20}
m1 <- glm(Default ~ log(DisbursementGross) + Term + 
        sqrt(NoEmp) + as.factor(NewExist) + as.factor(UrbanRural),
          data = sba, family = binomial)
summary(m1)
```

.large[
.question[
Why are the standard errors for NewExist so large?
]
]