---
title: Quasi-Poisson and negative binomial regression
output:
  xaringan::moon_reader:
    css: "lab-slides.css"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r include=F}
library(knitr)
library(tidyverse)
library(MASS)
library(foreign)
library(statmod)
library(gridExtra)

hook_output <- knit_hooks$get("output")
knit_hooks$set(output = function(x, options) {
   lines <- options$output.lines
   if (is.null(lines)) {
     return(hook_output(x, options))  # pass to default hook
   }
   x <- unlist(strsplit(x, "\n"))
   more <- "..."
   if (length(lines)==1) {        # first n lines
     if (length(x) > lines) {
       # truncate the output, but add ....
       x <- c(head(x, lines), more)
     }
   } else {
     x <- c(more, x[lines], more)
   }
   # paste these lines together
   x <- paste(c(x, ""), collapse = "\n")
   hook_output(x, options)
 })

heart_data <- read.csv("~/Documents/Teaching/sta214-f22.github.io/class_activities/framingham.csv")

heart_data <- heart_data %>%
  drop_na(male, age, education, diabetes, cigsPerDay, BMI) %>%
  mutate(education = as.factor(education))

```

### Warm-up: Class activity, Part I

.large[
[https://sta214-s23.github.io/class_activities/ca_lecture_23.html](https://sta214-s23.github.io/class_activities/ca_lecture_23.html)
]

---

### Class activity

.large[
```{r echo=F, warning=F, message=F, output.lines=25:26}
smokers <- heart_data %>%
  filter(currentSmoker == 1)

m1 <- glm(cigsPerDay ~ male + age + education + diabetes + BMI,
          data = smokers, family = poisson)
summary(m1)
```

**Goodness-of-fit test:**
]

---

### Class activity

```{r echo=F, warning=F, message=F, output.lines=23:27}
m2 <- glm(cigsPerDay ~ male + age + education + diabetes + BMI,
          data = smokers, family = quasipoisson)
summary(m2)
```

.large[
.question[
What is the estimated dispersion parameter $\widehat{\phi}$?
]
]

---

### Nested tests with quasi-Poisson models

```{r echo=F, warning=F, message=F, output.lines = 11:19}
summary(m2)
```

.large[
**Research question:** Is there a relationship between education level and the number of cigarettes smoked per day, after accounting for sex, age, diabetes, and BMI?

.question[
What are my null and alternative hypotheses for this research question?
]
]

---

### Nested tests with quasi-Poisson models

.large[
**Research question:** Is there a relationship between education level and the number of cigarettes smoked per day, after accounting for sex, age, diabetes, and BMI?

* In Poisson regression, we would use a likelihood ratio test
* However, the quasi-Poisson model includes the estimated dispersion, $\widehat{\phi}$. We need to use an **F-test** instead
]

---

### Nested tests with quasi-Poisson models

```{r}
m1 <- glm(cigsPerDay ~ male + age + education + 
            diabetes + BMI,
          data = smokers, family = quasipoisson)
m2 <- glm(cigsPerDay ~ male + age + diabetes + BMI,
          data = smokers, family = quasipoisson)

m1$deviance
m2$deviance
m1$df.residual
m2$df.residual
```


---

### Nested tests with quasi-Poisson models

.large[
```{r}
m1$deviance
m2$deviance

pf(0.258, 3, 2004, lower.tail=F)
```
]

---

### Alternative to quasi-Poisson: negative binomial

.large[
If $Y_i \sim NB(\theta, p)$, then $Y_i$ takes values $y = 0, 1, 2, 3, ...$ with probabilities

$$P(Y_i = y) = \dfrac{(y + \theta - 1)!}{y!(\theta - 1)!} (1 - p)^\theta p^y$$

* $\theta > 0$, $\ \ \ p \in [0, 1]$
* Mean = $\dfrac{p \theta}{1 - p} = \mu$
* Variance = $\dfrac{p \theta}{(1 - p)^2} = \mu + \dfrac{\mu^2}{\theta}$
* Variance is a *quadratic* function of the mean
]

---

### Negative binomial regression

.large[
$$Y_i \sim NB(\theta, \ p_i)$$

$$\log(\mu_i) = \beta_0 + \beta_1 X_i$$

* $\mu_i = \dfrac{p_i \theta}{1 - p_i}$
* Note that $\theta$ is the same for all $i$
* Note that just like in Poisson regression, we model the average count
  * Interpretation of $\beta$s is the same as in Poisson regression
]

---

### In R

.large[
```{r}
library(MASS)
m3 <- glm.nb(cigsPerDay ~ male + age + education + 
            diabetes + BMI, data = smokers)
```
]

```{r echo=F, message=F, warning=F, output.lines = c(10:19, 22:23)}
summary(m3)
```

---

### Fitted model

```{r echo=F, message=F, warning=F, output.lines = c(10:19, 22:23)}
summary(m3)
```

.large[
.question[
How do I interpret the estimated coefficient -0.007?
]
]

---

### Hypothesis testing

```{r echo=F, message=F, warning=F, output.lines = c(10:19, 22:23)}
summary(m3)
```

.large[
**Research question:** Is there a relationship between education level and the number of cigarettes smoked per day, after accounting for sex, age, diabetes, and BMI?
]

---

### Likelihood ratio test

.large[
```{r}
m3 <- glm.nb(cigsPerDay ~ male + age + education + 
               diabetes + BMI, data = smokers)
m4 <- glm.nb(cigsPerDay ~ male + age +
               diabetes + BMI, data = smokers)
m3$twologlik - m4$twologlik
pchisq(1.423, df=3, lower.tail=F)
```
]

---

### Comparing Poisson, quasi-Poisson, negative binomial

.large[
**Poisson:**

* Mean = $\lambda_i$
* Variance = $\lambda_i$

**quasi-Poisson:**

* Mean = $\lambda_i$
* Variance = $\phi \lambda_i$

**negative binomial:**

* Mean = $\mu_i$
* Variance = $\mu_i + \dfrac{\mu_i^2}{\theta}$
]

---

### Class activity, Part II

.large[
[https://sta214-s23.github.io/class_activities/ca_lecture_23.html](https://sta214-s23.github.io/class_activities/ca_lecture_23.html)
]

---

### Class activity

```{r, echo=F, message=F, warning=F, fig.width=10, fig.height=7.5,fig.align='center'}
r <- 1
x <- rnorm(1000, mean=0, sd=1.2)
y1 <- rpois(1000, lambda = exp(x))
y2 <- rnbinom(1000, size=r, mu=exp(x))

sim_m1 <- glm(y1 ~ x, family = poisson)
sim_m2 <- glm.nb(y1 ~ x)

p1 <- data.frame(x = x, resids = qresid(sim_m1)) %>%
  ggplot(aes(x = x, y = resids)) +
  geom_point() +
  geom_smooth() +
  labs(x = "X", y = "Quantile residuals",
       title = "Poisson regression on Poisson data") +
  theme_bw()

p2 <- data.frame(x = x, resids = qresid(sim_m2)) %>%
  ggplot(aes(x = x, y = resids)) +
  geom_point() +
  geom_smooth() +
  labs(x = "X", y = "Quantile residuals",
       title = "Negative binomial regression on Poisson data") +
  theme_bw()

sim_m1 <- glm(y2 ~ x, family = poisson)
sim_m2 <- glm.nb(y2 ~ x)

p3 <- data.frame(x = x, resids = qresid(sim_m1)) %>%
  ggplot(aes(x = x, y = resids)) +
  geom_point() +
  geom_smooth() +
  labs(x = "X", y = "Quantile residuals",
       title = "Poisson regression on negative binomial data") +
  theme_bw()

p4 <- data.frame(x = x, resids = qresid(sim_m2)) %>%
  ggplot(aes(x = x, y = resids)) +
  geom_point() +
  geom_smooth() +
  labs(x = "X", y = "Quantile residuals",
       title = "Negative binomial regression on negative binomial data") +
  theme_bw()

grid.arrange(p1, p2, p3, p4, ncol=2)
```

---

### Choosing a count model with quantile residual plots

.large[
* If the residuals have **constant variance** and mostly fall between **-2 and 2**: Poisson is reasonable
* If the residuals have **constant variance** but many residuals are $> 2$ or $< -2$: use either quasi-Poisson or negative binomial
* If the residuals have **non-constant variance**: use negative binomial
]

---

### quasi-Poisson vs. negative binomial

.large[

.pull-left[
**quasi-Poisson:**

* linear relationship between mean and variance
* easy to interpret $\widehat{\phi}$
* same as Poisson regression when $\phi = 1$
* simple adjustment to estimated standard errors
* estimated coefficients same as in Poisson regression
* $t$-tests and $F$-tests
]

.pull-right[
**negative binomial:**

* quadratic relationship between mean and variance
* we get to use a likelihood, rather than a quasi-likelihood
* Same as Poisson regression when $\theta$ is very large and $p$ is very small
* Wald tests and likelihood ratio tests
]
]