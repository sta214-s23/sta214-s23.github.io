---
title: "Class Activity, January 20"
output: 
  tufte::tufte_html:
    css: "lab.css"
    tufte_variant: "envisioned"
    highlight: pygments
link-citations: yes
---

In this class activity, you will practice maximum likelihood estimation.

Suppose we have a variable $Y$ that can take **three** possible outcomes: $Y = -1, 0$, or $1$. We also know that

* $P(Y_i = 0) = \pi_0$
* $P(Y_i = -1) = 2 \pi_0$
* $P(Y_i = 1) = 1 - 3 \pi_0$

where the parameter $\pi_0$ is unknown. We observe data $-1, -1, 0, 1, 0, -1$, and we want to estimate $\pi_0$ from the data.

# Questions


1. Let $\widehat{\pi}_0$ be an estimate of $\pi_0$. Write down the likelihood $L(\widehat{\pi}_0)$ for the observed data $-1, -1, 0, 1, 0, -1$.

2. Use calculus to maximize the likelihood from Exercise 1. Remember to differentiate the log likelihood, and recall the following rules for logs and derivatives:

* $\log(xy) = \log(x) + \log(y)$
* $\log(x^y) = y \log(x)$
* $\dfrac{d}{dx} \log x = \dfrac{1}{x}$
* $\dfrac{d}{dx} c f(x) = c \dfrac{d}{dx} f(x)$ for constant $c$
* $\dfrac{d}{dx} (f(x) + c) = \dfrac{d}{dx} f(x)$ for constant $c$
* $\dfrac{d}{dx} (f(x) + g(x)) = \dfrac{d}{dx} f(x) + \dfrac{d}{dx} g(x)$