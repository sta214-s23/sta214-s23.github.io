---
title: "Class Activity, February 3"
output: 
  tufte::tufte_html:
    css: "lab.css"
    tufte_variant: "envisioned"
    highlight: pygments
link-citations: yes
---

# Part I

In the first part of this class activity, we will return to the `titanic` data we have seen on HW and in class:

```{r, eval=F}
titanic <- read.csv("https://sta214-s23.github.io/homework/Titanic.csv")
```

Let's consider a variable we haven't worked with yet: Fare. Our model is

$Survived \sim Bernoulli(\pi_i)$

$\log \left( \dfrac{\pi_i}{1 - \pi_i} \right) = \beta_0 + \beta_1 Fare_i$

## Questions

The code below will make an empirical logit plot with Fare as the explanatory variable, Survived as the binary response, and 30 bins:

```{r, eval=F}
library(tidyverse)
logodds_plot <- function(data, num_bins, bin_method,
                         x_name, y_name, grouping = NULL, reg_formula = y ~ x){
  
  if(is.null(grouping)){
    dat <- data.frame(x = data %>% pull(x_name), 
                      y = data %>% pull(y_name),
                      group = 1)
  } else {
    dat <- data.frame(x = data %>% pull(x_name), 
                      y = data %>% pull(y_name),
                      group = as.factor(data %>% pull(grouping)))
  }
  
  if(bin_method == "equal_size"){
    logodds_table <- dat %>%
      drop_na() %>%
      arrange(group, x) %>%
      group_by(group) %>%
      mutate(obs = y,
             bin = rep(1:num_bins,
                       each=ceiling(n()/num_bins))[1:n()]) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  } else {
    logodds_table <- dat %>%
      drop_na() %>%
      group_by(group) %>%
      mutate(obs = y,
             bin = cut(x, 
                       breaks = num_bins,
                       labels = F)) %>%
      group_by(bin, group) %>%
      summarize(mean_x = mean(x),
                prop = mean(c(obs, 0.5)),
                num_obs = n()) %>%
      ungroup() %>%
      mutate(logodds = log(prop/(1 - prop)))
  }
  
  if(is.null(grouping)){
    logodds_table %>%
      ggplot(aes(x = mean_x,
                 y = logodds)) +
      geom_point(size=2) +
      geom_smooth(se=F, method="lm", formula = reg_formula) +
      theme_bw() +
      labs(x = x_name,
           y = "Empirical log odds") +
      theme(text = element_text(size=15))
  } else {
    logodds_table %>%
      ggplot(aes(x = mean_x,
                 y = logodds,
                 color = group,
                 shape = group)) +
      geom_point(size=2) +
      geom_smooth(se=F, method="lm", formula = reg_formula) +
      theme_bw() +
      labs(x = x_name,
           y = "Empirical log odds",
           color = grouping,
           shape = grouping) +
      theme(text = element_text(size=15))
  }
}

logodds_plot(titanic, 30, "equal_size", "Fare", "Survived", reg_formula = y ~ x)
```

1. Run the code to produce the empirical logit plot. Does it look like their is a linear relationship between Fare and the log odds of survival? Experiment with the number of bins in the final line of the code to be sure.

2. You can try different transformations of Fare in the empirical logit plot by changing the regression formula (the `reg_formula` argument). For example, you could try `y ~ sqrt(x)`, or `y ~ log(x)`. Experiment with a few different transformations -- which ones seem reasonable?

# Part II

In the second part of this class activity, we will explore quantile residuals as a diagnostic tool for logistic regression. Quantile residuals can be calculated for a fitted GLM in R using the `qresid()` function in the `statmod` package (you may need to install this package).

Here is some code to simulate data for which the logistic regression model assumptions hold:

```r
library(tidyverse)
library(statmod)

# simulate a single explanatory variable from a Normal distribution
x <- rnorm(1000)

# create P(Y = 1 | X) for each entry in x
# Here log odds = -1 + 2x
p <- exp(-1 + 2*x)/(1 + exp(-1 + 2*x))

# Finally, simulate a binary response at each x
y <- rbinom(1000, 1, p)

# fit the model and plot the quantile residuals against x
# add a smooth fit to see if there is a relationship
m1 <- glm(y ~ x, family = binomial)
data.frame(x = x, residuals = qresid(m1)) %>%
  ggplot(aes(x = x, y = residuals)) +
  geom_point() +
  geom_smooth() +
  theme_bw()
```

## Questions

1. Run the code above to simulate data, fit the model, and generate the quantile residual plot. Confirm that when the logistic regression assumptions are satisfied, the quantile residual plot looks good.

2. Modify the simulation code above so that the log odds are *not* a linear function of $X$. Fit the same logistic regression model as above (`y ~ x`, which is now wrong) and make a quantile residual plot. Does the plot show that the assumptions are violated?

